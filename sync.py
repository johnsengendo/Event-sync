# Importing necessary libraries
import numpy as np
import pandas as pd
from filterpy.kalman import KalmanFilter
import gymnasium as gym
from gymnasium import spaces
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
import seaborn as sns
from matplotlib.patches import Rectangle
import os
from typing import Dict, List, Tuple, Callable, Any

# Setting high DPI for all plots with enhanced text properties
plt.rcParams['figure.dpi'] = 1200
plt.rcParams['savefig.dpi'] = 1200
plt.rcParams['figure.figsize'] = (12, 8)
# Enhanced font settings for bold and clear text
plt.rcParams['font.weight'] = 'bold'
plt.rcParams['axes.labelweight'] = 'bold'
plt.rcParams['axes.titleweight'] = 'bold'
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
plt.rcParams['legend.fontsize'] = 12
plt.rcParams['figure.titlesize'] = 18
plt.rcParams['axes.linewidth'] = 2
plt.rcParams['xtick.major.width'] = 2
plt.rcParams['ytick.major.width'] = 2
plt.rcParams['xtick.minor.width'] = 1.5
plt.rcParams['ytick.minor.width'] = 1.5

# Defining the orange and dark blue colors to match your image
ORANGE_COLOR = '#FF9500'  # Bright orange
BLUE_COLOR = '#003f7f'    # Dark blue
GREEN_COLOR = '#27ae60'   # New green
PURPLE_COLOR = '#8e44ad'  # New purple

# Defining a function to load data from a CSV file
def load_data(filename='results.csv'):
    # Getting the directory where the script is located
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # Constructing the full file path
    file_path = os.path.join(script_dir, filename)
    # Loading the data from the CSV file
    df = pd.read_csv(file_path)
    print("We are loading the data successfully. Here are the first few rows:")
    print(df.head())
    # Returning the packet per second values as a numpy array
    return df["packets_per_sec"].values

# Loading the data
data = load_data()
dt = 1  # We are setting the time steps in seconds

# Defining an adaptive event-based synchronization method
def adaptive_event_sync(pt, initial_thr, drift, adaptive_factor=0.1):
    # Initializing state and synchronization indices
    state, idx = [pt[0]], []
    thr = initial_thr
    # Iterating through the time series
    for i in range(1, len(pt)):
        # Checking if the current value differs from the last state by more than the threshold
        if abs(pt[i] - state[-1]) > thr:
            # Synchronizing to the current value
            state.append(pt[i])
            idx.append(i)
            thr = max(initial_thr, thr - adaptive_factor)
        else:
            # Drifting the state if not synchronizing
            state.append(state[-1] + drift * dt)
            thr = min(initial_thr * 2, thr + adaptive_factor)
    return np.array(state), idx

# Defining a Model Predictive Control synchronization method
def mpc_sync(pt, drift, horizon, cost, max_drift_error=1.0):
    # Initializing state and synchronization indices
    state, idx = [pt[0]], []
    # Iterating through the time series
    for i in range(1, len(pt)):
        # Predicting the next state
        pred_state = state[-1] + drift * dt
        err = abs(pt[i] - pred_state)
        # If the drift-error exceeds max_drift_error, we are forcing a sync
        if err > max_drift_error:
            state.append(pt[i])
            idx.append(i)
            continue
        # Calculating the cost of synchronization
        c_sync = cost + abs(pt[i] - state[-1])
        # Calculating the cost of drifting
        c_drift = sum(
            abs(pt[i + h] - (state[-1] + drift * (h + 1) * dt))
            for h in range(horizon) if i + h < len(pt)
        )
        # Deciding whether to synchronize or drift based on cost
        if c_sync < c_drift:
            state.append(pt[i])
            idx.append(i)
        else:
            state.append(pred_state)
    return np.array(state), idx

# Defining a Kalman Filter synchronization method
def kalman_sync(pt, proc_var, meas_var):
    # Initializing the Kalman filter
    kf = KalmanFilter(dim_x=1, dim_z=1)
    kf.x = np.array([pt[0]])
    kf.F = kf.H = np.array([[1]])
    kf.P *= 1000
    kf.Q = proc_var
    kf.R = meas_var
    # Initializing state and synchronization indices
    state, idx = [pt[0]], []
    # Iterating through the time series
    for i, z in enumerate(pt[1:], 1):
        kf.predict()
        # Checking if the measurement is significantly different from the prediction
        if abs(z - kf.x[0]) > 3 * np.sqrt(kf.P[0, 0]):
            kf.x = np.array([z])
            idx.append(i)
        kf.update(z)
        state.append(kf.x[0])
    return np.array(state), idx

# Defining a custom Gym environment for synchronization tasks
class SyncEnv(gym.Env):
    def __init__(self, pt, window=5):
        super().__init__()
        self.pt = pt  # We are setting the input time series
        self.window = window  # We are setting the window size for calculating variance
        # Defining action and observation spaces
        self.action_space = spaces.Box(0.0, 1.0, (1,), np.float32)
        self.observation_space = spaces.Box(-np.inf, np.inf, (5,), np.float32)
        # Precomputing derivative and variance
        self._deriv = np.gradient(pt)
        self._var = np.array([np.var(pt[max(0,i-window):i+1]) for i in range(len(pt))])

    def reset(self, seed=None, options=None):
        # Resetting the environment to the initial state
        super().reset(seed=seed)
        self.t = 0  # We are setting the current time step
        self.state = self.pt[0]
        self.last = 0  # We are setting the last synchronization time
        self.last_action = 0.0  # We are setting the last action taken
        return self._obs(), {}

    def _obs(self):
        # Getting the current observation
        err = self.pt[self.t] - self.state
        time_since = (self.t - self.last) * dt
        return np.array([err, time_since, self.last_action, self._deriv[self.t], self._var[self.t]], np.float32)

    def step(self, action):
        # Converting action to threshold factor
        factor = float(np.clip(action, 0, 1))
        thr = 1.0 + factor * 4.0
        # Calculating the current error
        err = abs(self.pt[self.t] - self.state)
        # Determining if we should synchronize
        sync = err > thr
        if sync:
            # Synchronizing
            self.state = self.pt[self.t]
            self.last = self.t
            event_bonus = 0.5
        else:
            # Drifting the state
            self.state += 0.05 * dt
            event_bonus = 0.0
        # Calculating the reward
        reward = -err**2 + event_bonus - 0.2*factor
        # Updating the last action
        self.last_action = factor
        # Checking if the episode is done
        done = self.t >= len(self.pt)-2
        # Moving to the next time step
        self.t += 1
        return self._obs(), reward, done, False, {}

# Defining a function to train a PPO model for synchronization
def train_rl(pt, timesteps=300_000):
    """
    Train a PPO model for synchronization tasks.
    """
    # Creating an environment function
    def make_env():
        return Monitor(SyncEnv(pt))

    # Creating a vectorized environment
    venv = VecNormalize(DummyVecEnv([make_env]), norm_obs=True, norm_reward=False)

    # Creating PPO model
    model = PPO(
        'MlpPolicy', 
        venv, 
        learning_rate=5e-5, 
        n_steps=2048, 
        batch_size=128, 
        n_epochs=10,
        gamma=0.995, 
        gae_lambda=0.9, 
        policy_kwargs=dict(net_arch=[256,256]), 
        verbose=1
    )

    # Creating an evaluation callback
    cb = EvalCallback(
        venv, 
        best_model_save_path='./best', 
        eval_freq=10_000,
        callback_after_eval=StopTrainingOnNoModelImprovement(20,30)
    )

    # Training the model
    model.learn(total_timesteps=timesteps, callback=cb)
    return model, venv

# Defining a PPO-based synchronization method
def rl_event_sync(pt, drift, rl_model, venv):
    # Initializing state and synchronization indices
    state, idx = [pt[0]], []
    # Resetting the environment
    obs = venv.reset()
    # Iterating through the time series
    for i in range(1, len(pt)):
        # Getting action from the PPO model
        action, _ = rl_model.predict(obs, deterministic=True)
        # Stepping the environment
        obs, _, _, _ = venv.step(action)
        # Converting action to threshold factor
        factor = float(np.clip(action, 0, 1))
        thr = 1 + factor * 4
        # Checking if we should synchronize
        if abs(pt[i] - state[-1]) > thr:
            # Synchronizing
            state.append(pt[i])
            idx.append(i)
        else:
            # Drifting
            state.append(state[-1] + drift * dt)
    return np.array(state), idx

# Defining a function to evaluate synchronization methods
def evaluate(pt, methods):
    results = []
    # Evaluating each method
    for name, fn in methods.items():
        state, idx = fn()
        # Calculating metrics
        mae = np.mean(np.abs(pt - state))
        rmse = np.sqrt(np.mean((pt - state)**2))
        results.append({
            'method': name,
            'mae': mae,
            'rmse': rmse,
            'syncs': len(idx)
        })
    return results

# Enhanced box plot functions focusing only on RMSE and MAE
def run_multiple_evaluations(pt, methods, ppo_model=None, ppo_env=None, n_runs=50, noise_levels=[0.1, 0.2, 0.3]):
    """
    Run multiple evaluations with different noise levels and parameter variations
    to generate distributions for box plots.
    """
    all_results = {method_name: {'mae': [], 'rmse': []} for method_name in methods.keys()}
    
    for run in range(n_runs):
        # Adding slight noise to data for variation
        noise_level = np.random.choice(noise_levels)
        noisy_data = pt + np.random.normal(0, noise_level * np.std(pt), len(pt))
        
        # Vary parameters slightly for each method
        varied_methods = {}
        
        # Adaptive Event-Based with parameter variation
        initial_thr = np.random.uniform(1.5, 2.5)
        drift = np.random.uniform(0.03, 0.07)
        adaptive_factor = np.random.uniform(0.08, 0.12)
        varied_methods['Adaptive Event-Based'] = lambda: adaptive_event_sync(
            noisy_data, initial_thr, drift, adaptive_factor
        )
        
        # MPC with parameter variation
        drift_mpc = np.random.uniform(0.03, 0.07)
        horizon = np.random.choice([3, 4, 5, 6, 7])
        cost = np.random.uniform(2.5, 3.5)
        max_drift_error = np.random.uniform(0.8, 1.2)
        varied_methods['MPC'] = lambda: mpc_sync(
            noisy_data, drift_mpc, horizon, cost, max_drift_error
        )
        
        # Kalman with parameter variation
        proc_var = np.random.uniform(0.08, 0.12)
        meas_var = np.random.uniform(0.8, 1.2)
        varied_methods['Kalman'] = lambda: kalman_sync(noisy_data, proc_var, meas_var)
        
        # RL (if available)
        if 'RL' in methods and ppo_model is not None and ppo_env is not None:
            drift_rl = np.random.uniform(0.03, 0.07)
            varied_methods['RL'] = lambda: rl_event_sync(noisy_data, drift_rl, ppo_model, ppo_env)
        
        # Evaluating each method for this run
        for method_name, method_func in varied_methods.items():
            if method_name in methods:  # Only evaluate if method exists
                try:
                    state, idx = method_func()
                    mae = np.mean(np.abs(noisy_data - state))
                    rmse = np.sqrt(np.mean((noisy_data - state)**2))
                    
                    all_results[method_name]['mae'].append(mae)
                    all_results[method_name]['rmse'].append(rmse)
                except Exception as e:
                    print(f"Error in {method_name} run {run}: {e}")
                    continue
    
    return all_results

def create_perfect_box_plot(all_results, save_dir, dpi=1200):
    """
    Create a perfect box plot with enhanced styling and statistical annotations.
    Focuses only on RMSE and MAE with orange and blue colors and bold labels.
    """
    plt.style.use('seaborn-v0_8-whitegrid')
    
    # Preparing data for plotting
    methods = list(all_results.keys())
    mae_data = [all_results[method]['mae'] for method in methods]
    rmse_data = [all_results[method]['rmse'] for method in methods]
    
    # Creating figure with two subplots
    fig, axes = plt.subplots(1, 2, figsize=(18, 10), dpi=dpi)
    
    # MAE Box Plot
    bp1 = axes[0].boxplot(mae_data, labels=methods, patch_artist=True, 
                         showmeans=True, meanline=True,
                         boxprops=dict(linewidth=3),
                         whiskerprops=dict(linewidth=3),
                         capprops=dict(linewidth=3),
                         medianprops=dict(linewidth=4, color='black'),
                         meanprops=dict(linewidth=4, color='red', linestyle='--'))
    
    # Color mapping per method for box fills
    colors_map = {
        'Adaptive Event-Based': ORANGE_COLOR,   
        'MPC': BLUE_COLOR,                   
        'Kalman': GREEN_COLOR,                  
        'RL': PURPLE_COLOR                        
    }
    
    # Color the boxes using the mapping (MAE)
    for i, patch in enumerate(bp1['boxes']):
        patch.set_facecolor(colors_map.get(methods[i], ORANGE_COLOR))
        patch.set_alpha(0.8)
        patch.set_edgecolor('black')
        patch.set_linewidth(3)
    
    axes[0].set_title('Mean Absolute Error (MAE) Distribution', 
                     fontsize=24, fontweight='bold', pad=25)
    axes[0].set_ylabel('MAE', fontsize=20, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    
    # RMSE Box Plot
    bp2 = axes[1].boxplot(rmse_data, labels=methods, patch_artist=True,
                         showmeans=True, meanline=True,
                         boxprops=dict(linewidth=3),
                         whiskerprops=dict(linewidth=3),
                         capprops=dict(linewidth=3),
                         medianprops=dict(linewidth=4, color='black'),
                         meanprops=dict(linewidth=4, color='red', linestyle='--'))
    
    # Color the boxes using the same mapping (RMSE)
    for i, patch in enumerate(bp2['boxes']):
        patch.set_facecolor(colors_map.get(methods[i], ORANGE_COLOR))
        patch.set_alpha(0.8)
        patch.set_edgecolor('black')
        patch.set_linewidth(3)
    
    axes[1].set_title('Root Mean Square Error (RMSE) Distribution', 
                     fontsize=24, fontweight='bold', pad=25)
    axes[1].set_ylabel('RMSE', fontsize=20, fontweight='bold')
    axes[1].grid(True, alpha=0.3)
    
    # Enhanced styling for all subplots
    for ax in axes:
        ax.set_xlabel('Synchronization Method', fontsize=20, fontweight='bold')
        ax.tick_params(axis='x', labelsize=16, rotation=15, width=3, labelcolor='black')
        ax.tick_params(axis='y', labelsize=16, width=3, labelcolor='black')
        
        # Making tick labels bold
        for label in ax.get_xticklabels():
            label.set_fontweight('bold')
        for label in ax.get_yticklabels():
            label.set_fontweight('bold')
        
        # Enhanced spines
        for spine in ax.spines.values():
            spine.set_linewidth(3)
    
    # Adding legend explaining the box plot elements
    legend_elements = [
        plt.Line2D([0], [0], color='black', linewidth=4, label='Median'),
        plt.Line2D([0], [0], color='red', linewidth=4, linestyle='--', label='Mean'),
    ]
    
    fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02),
              ncol=3, fontsize=16, frameon=True, fancybox=True, shadow=True, prop={'weight': 'bold'})
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.85, bottom=0.12)
    
    # Saving the plot
    plot_path = os.path.join(save_dir, 'performance_boxplot_perfect.png')
    plt.savefig(plot_path, dpi=dpi, bbox_inches='tight', facecolor='white')
    plt.close()
    
    return plot_path

def print_statistical_summary(all_results):
    """
    Print detailed statistical summary of the results.
    """
    print("\n" + "="*80)
    print("DETAILED STATISTICAL SUMMARY")
    print("="*80)
    
    for method in all_results:
        print(f"\n{method.upper()} METHOD:")
        print("-" * 50)
        
        for metric in ['mae', 'rmse']:
            data = np.array(all_results[method][metric])
            print(f"{metric.upper()}:")
            print(f"  Mean: {np.mean(data):.4f}")
            print(f"  Median: {np.median(data):.4f}")
            print(f"  Std Dev: {np.std(data):.4f}")
            print(f"  Min: {np.min(data):.4f}")
            print(f"  Max: {np.max(data):.4f}")
            print(f"  25th Percentile: {np.percentile(data, 25):.4f}")
            print(f"  75th Percentile: {np.percentile(data, 75):.4f}")
            print(f"  IQR: {np.percentile(data, 75) - np.percentile(data, 25):.4f}")
            print()

# Plotting functions with enhanced styling using orange and blue colors
def plot_comparison(results, save_dir, dpi=1200):
    names = [r['method'] for r in results]
    mae_vals = [r['mae'] for r in results]
    rmse_vals = [r['rmse'] for r in results]

    bar_width = 0.35
    r1 = np.arange(len(names))
    r2 = r1 + bar_width

    fig, ax = plt.subplots(figsize=(16, 12), dpi=dpi)
    
    # Using orange and blue colors for bars
    bars1 = ax.bar(r1, mae_vals, width=bar_width, label='MAE', 
                   color=ORANGE_COLOR, edgecolor='black', linewidth=2.5, alpha=0.8)
    bars2 = ax.bar(r2, rmse_vals, width=bar_width, label='RMSE', 
                   color=BLUE_COLOR, edgecolor='black', linewidth=2.5, alpha=0.8)

    ax.set_xlabel('Synchronization method', fontsize=22, fontweight='bold')
    ax.set_ylabel('Error magnitude', fontsize=22, fontweight='bold')
    ax.set_title('Performance evaluation: MAE and RMSE', fontsize=26, fontweight='bold')
    ax.set_xticks(r1 + bar_width/2)
    ax.set_xticklabels(names, fontsize=18, fontweight='bold')
    ax.tick_params(axis='y', labelsize=18, width=3, labelcolor='black')

    # Making all tick labels bold
    for label in ax.get_xticklabels():
        label.set_fontweight('bold')
    for label in ax.get_yticklabels():
        label.set_fontweight('bold')

    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.3f}'))

    legend = ax.legend(fontsize=18, prop={'weight': 'bold'})
    ax.grid(True, alpha=0.3)

    # Enhanced spines
    for spine in ax.spines.values():
        spine.set_linewidth(3)

    fig.tight_layout()
    plt.savefig(os.path.join(save_dir, 'performance_comparison_hd.png'), dpi=dpi, bbox_inches='tight')
    plt.close()

def plot_sync_counts(results, save_dir, dpi=1200):
    names = [r['method'] for r in results]
    counts = [r['syncs'] for r in results]

    fig, ax = plt.subplots(figsize=(16, 12), dpi=dpi)
    
    colors_map = {
        'Adaptive Event-Based': BLUE_COLOR,
        'MPC': BLUE_COLOR,
        'Kalman': BLUE_COLOR,
        'RL': BLUE_COLOR      
    }
    colors = [colors_map.get(n, BLUE_COLOR) for n in names]
    
    bars = ax.bar(names, counts, edgecolor='black', linewidth=2.5, 
                  color=colors, alpha=0.8)

    ax.set_xlabel('Synchronization method', fontsize=22, fontweight='bold')
    ax.set_ylabel('Number of Sync events', fontsize=22, fontweight='bold')
    ax.set_title('Synchronization event frequency', fontsize=26, fontweight='bold')
    ax.set_xticklabels(names, fontsize=18, fontweight='bold')
    ax.tick_params(axis='y', labelsize=18, width=3, labelcolor='black')

    # Making all tick labels bold
    for label in ax.get_xticklabels():
        label.set_fontweight('bold')
    for label in ax.get_yticklabels():
        label.set_fontweight('bold')

    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))
    ax.grid(True, axis='y', alpha=0.3)

    # Enhanced spines
    for spine in ax.spines.values():
        spine.set_linewidth(3)

    fig.tight_layout()
    plt.savefig(os.path.join(save_dir, 'sync_counts_hd.png'), dpi=dpi, bbox_inches='tight')
    plt.close()

def plot_cumulative_error(pt, methods, save_dir, dpi=1200):
    t = np.arange(len(pt))
    fig, ax = plt.subplots(figsize=(22, 14), dpi=dpi)

    # Using orange and blue colors for lines
    colors = {
        'Adaptive Event-Based': ORANGE_COLOR,
        'MPC': BLUE_COLOR,
        'Kalman': GREEN_COLOR,
        'RL': PURPLE_COLOR
    }

    line_styles = {
        'Adaptive Event-Based': (0, (12, 6)),
        'MPC': (0, (16, 8, 4, 8)),
        'Kalman': (0, (8, 4)),
        'RL': (0, (20, 6, 4, 6, 4, 6))
    }

    for name, fn in methods.items():
        state, _ = fn()
        cum_err = np.cumsum(np.abs(pt - state))

        ax.plot(t, cum_err, label=name,
                color=colors.get(name, '#333333'),
                linestyle=line_styles.get(name, '--'),
                linewidth=7.5, alpha=0.9)

    ax.set_title('Cumulative absolute error over time', fontsize=32, fontweight='bold', pad=35)
    ax.set_xlabel('Time (seconds)', fontsize=28, fontweight='bold', labelpad=25)
    ax.set_ylabel('Cumulative error', fontsize=28, fontweight='bold', labelpad=25)
    ax.tick_params(axis='both', labelsize=22, width=3, labelcolor='black')
    ax.tick_params(axis='both', which='minor', width=2, length=8)

    # Making all tick labels bold
    for label in ax.get_xticklabels():
        label.set_fontweight('bold')
    for label in ax.get_yticklabels():
        label.set_fontweight('bold')

    legend = ax.legend(fontsize=24, frameon=True, fancybox=True, shadow=True,
                       loc='upper left', framealpha=0.95, prop={'weight': 'bold'})
    legend.get_frame().set_linewidth(3)
    legend.get_frame().set_edgecolor('black')
    ax.grid(True, alpha=0.4, linewidth=2)
    ax.set_axisbelow(True)

    for spine in ax.spines.values():
        spine.set_linewidth(3)

    fig.tight_layout()
    plt.savefig(os.path.join(save_dir, 'cumulative_error_hd.png'), dpi=dpi, bbox_inches='tight')
    plt.close()

def calculate_information_metrics(pt, methods, bits_per_sync=32):
    info_metrics = []
    # Calculating information metrics for each method
    for name, fn in methods.items():
        state, idx = fn()
        # Calculating metrics
        total_bits = len(idx) * bits_per_sync
        bits_per_time = total_bits / (len(pt) * dt)
        mae = np.mean(np.abs(pt - state))
        error_info_tradeoff = mae * (total_bits / len(pt))
        info_metrics.append({
            'method': name,
            'total_bits': total_bits,
            'bits_per_time': bits_per_time,
            'error_info_tradeoff': error_info_tradeoff,
            'mae': mae
        })
    return info_metrics

def plot_information_metrics(info_metrics, save_dir, dpi=1200):
    plt.style.use('seaborn-v0_8-whitegrid')
    # Extracting data
    methods = [m['method'] for m in info_metrics]
    total_bits = [m['total_bits'] for m in info_metrics]
    bits_per_time = [m['bits_per_time'] for m in info_metrics]
    error_info = [m['error_info_tradeoff'] for m in info_metrics]
    # Creating figure with enhanced sizing
    fig, axes = plt.subplots(1, 3, figsize=(28, 12), dpi=dpi)
    # Enhanced color palette with orange and blue
    colors = [ORANGE_COLOR if i % 2 == 0 else BLUE_COLOR for i in range(len(methods))]
    
    # Plotting total bits transmitted
    bars1 = axes[0].bar(methods, total_bits, color=colors, alpha=0.85,
                        edgecolor='black', linewidth=3)
    axes[0].set_title('Total Information transmitted (bits)',
                      fontsize=22, fontweight='bold', color='#2c3e50', pad=25)
    axes[0].set_ylabel('Bits', fontsize=20, fontweight='bold', color='#2c3e50', labelpad=20)
    axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))
    axes[0].set_ylim(0, max(total_bits) * 1.2)
    
    # Plotting bits per time unit
    bars2 = axes[1].bar(methods, bits_per_time, color=colors, alpha=0.85,
                        edgecolor='black', linewidth=3)
    axes[1].set_title('Communication bandwidth (bits per time unit)',
                      fontsize=22, fontweight='bold', color='#2c3e50', pad=25)
    axes[1].set_ylabel('Bits/Time', fontsize=20, fontweight='bold', color='#2c3e50', labelpad=20)
    axes[1].set_ylim(0, max(bits_per_time) * 1.2)
    
    # Plotting error-information tradeoff
    bars3 = axes[2].bar(methods, error_info, color=colors, alpha=0.85,
                        edgecolor='black', linewidth=3)
    axes[2].set_title('Error-Information tradeoff',
                      fontsize=22, fontweight='bold', color='#2c3e50', pad=25)
    axes[2].set_ylabel('MAE √ó Bits/sample', fontsize=20, fontweight='bold', color='#2c3e50', labelpad=20)
    axes[2].set_ylim(0, max(error_info) * 1.2)
    
    # Enhancing styling for all subplots
    for ax in axes:
        ax.set_xlabel('Synchronization method', fontsize=20, fontweight='bold', color='#2c3e50', labelpad=20)
        ax.tick_params(axis='x', labelsize=16, rotation=15, width=3, labelcolor='black')
        ax.tick_params(axis='y', labelsize=16, width=3, labelcolor='black')
        
        # Making all tick labels bold
        for label in ax.get_xticklabels():
            label.set_fontweight('bold')
        for label in ax.get_yticklabels():
            label.set_fontweight('bold')
        
        ax.grid(True, alpha=0.4, linestyle='-', linewidth=1.5)
        ax.set_axisbelow(True)

        for spine in ax.spines.values():
            spine.set_linewidth(3)
        ax.set_facecolor('#fafafa')
    
    plt.tight_layout()
    plt.suptitle('Information transfer analysis',
                 fontsize=26, fontweight='bold', color='#2c3e50', y=0.98)
    plt.subplots_adjust(top=0.88)
    
    # Saving the plot
    plot_path = os.path.join(save_dir, 'information_metrics.png')
    plt.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close()

def plot_error_vs_information(info_metrics, save_dir, dpi=1200):
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(16, 12), dpi=dpi)
    # Extracting data
    methods = [m['method'] for m in info_metrics]
    mae = [m['mae'] for m in info_metrics]
    bits_per_sample = [m['total_bits']/len(data) for m in info_metrics]
    # Colors for scatter points (orange and blue)
    colors = [ORANGE_COLOR if i % 2 == 0 else BLUE_COLOR for i in range(len(methods))]
    
    # Creating enhanced scatter plot
    for i, (method, x, y) in enumerate(zip(methods, bits_per_sample, mae)):
        ax.scatter(x, y, s=300, color=colors[i], alpha=0.8,
                   edgecolor='black', linewidth=3, label=method, zorder=5)
        ax.text(x+0.025, y, method, fontsize=16, fontweight='bold',
                bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8))
    
    # Plot styling
    ax.set_title('Error vs Information transfer trade-off',
                 fontsize=26, fontweight='bold', color='#2c3e50', pad=30)
    ax.set_xlabel('Information transfer (bits per sample)',
                 fontsize=22, fontweight='bold', color='#2c3e50', labelpad=20)
    ax.set_ylabel('Mean Absolute Error (MAE)',
                 fontsize=22, fontweight='bold', color='#2c3e50', labelpad=20)

    ax.grid(True, alpha=0.4, linestyle='-', linewidth=1.5)
    ax.set_axisbelow(True)
    
    # Enhanced explanatory text
    ax.text(0.02, 0.02,
            "Better methods are closer to the origin (lower error, lower bits)",
            transform=ax.transAxes, fontsize=16, fontstyle='italic', fontweight='bold',
            bbox=dict(boxstyle="round,pad=0.5", facecolor='lightyellow', alpha=0.8))
    
    # Setting axis limits with padding
    x_max = max(bits_per_sample) * 1.25
    y_max = max(mae) * 1.25
    ax.set_xlim(0, x_max)
    ax.set_ylim(0, y_max)
    
    # Making all tick labels bold
    for label in ax.get_xticklabels():
        label.set_fontweight('bold')
    for label in ax.get_yticklabels():
        label.set_fontweight('bold')
    
    # Spines
    for spine in ax.spines.values():
        spine.set_linewidth(3)
    ax.set_facecolor('#fafafa')

    ax.tick_params(axis='both', labelsize=18, width=3, labelcolor='black')
    plt.tight_layout()
    
    # Saving the plot
    plot_path = os.path.join(save_dir, 'error_vs_information.png')
    plt.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close()

def track_information_transmission(pt, methods, bits_per_sync=32):
    info_tracking = {}
    # Tracking information transmission for each method
    for name, fn in methods.items():
        state, idx = fn()
        # Tracking information transmission
        sync_times = [i * dt for i in idx]
        cumulative_bits = [bits_per_sync * (i+1) for i in range(len(idx))]
        sync_values = [pt[i] for i in idx]
        info_tracking[name] = {
            'sync_times': sync_times,
            'cumulative_bits': cumulative_bits,
            'sync_values': sync_values,
            'total_bits': bits_per_sync * len(idx)
        }
    return info_tracking

def plot_information_per_sync_event_hd(info_tracking, save_dir, dpi=1200):
    plt.style.use('seaborn-v0_8-whitegrid')
    # Creating figure with enhanced higher DPI
    fig, ax = plt.subplots(figsize=(22, 14), dpi=dpi)
    # Enhanced color palette with orange and blue
    colors = {
        'Adaptive Event-Based': ORANGE_COLOR,
        'MPC': BLUE_COLOR,
        'Kalman': GREEN_COLOR,
        'RL': PURPLE_COLOR
    }
    # Dash patterns - bigger and more visible
    line_styles = {
        'Adaptive Event-Based': (0, (15, 8)),
        'MPC': (0, (18, 10, 4, 10)),
        'Kalman': (0, (10, 5)),
        'RL': (0, (25, 8, 5, 8, 5, 8))
    }
    # Plotting each method with enhanced styling (no markers)
    for name, data in info_tracking.items():
        ax.plot(data['sync_times'], data['cumulative_bits'],
                label=name, color=colors.get(name, '#333333'),
                linestyle=line_styles.get(name, '--'),
                linewidth=7.5, alpha=0.9, zorder=2)
    
    # Setting title and labels
    ax.set_title('Information transmitted at each synchronization event',
                 fontsize=32, fontweight='bold', color="#000000", pad=40)
    ax.set_xlabel('Time (seconds)', fontsize=28, fontweight='bold',
                  color="#000000", labelpad=25)
    ax.set_ylabel('Cumulative bits transmitted', fontsize=28, fontweight='bold',
                  color="#000000", labelpad=25)
    
    # Adding grid
    ax.grid(True, alpha=0.4, linestyle='-', linewidth=2)
    ax.set_axisbelow(True)
    
    # Adding legend
    legend = ax.legend(loc='upper left', fontsize=22, frameon=True,
                       fancybox=True, shadow=True, framealpha=0.95,
                       edgecolor='black', facecolor='white', prop={'weight': 'bold'})
    legend.get_frame().set_linewidth(3)
    
    # Setting axis limits with enhanced padding
    if info_tracking:
        max_time = max(max(data['sync_times']) for data in info_tracking.values() if data['sync_times'])
        max_bits = max(max(data['cumulative_bits']) for data in info_tracking.values() if data['cumulative_bits'])
        ax.set_xlim(0, max_time * 1.08)
        ax.set_ylim(0, max_bits * 1.12)
    
    # Making all tick labels bold
    for label in ax.get_xticklabels():
        label.set_fontweight('bold')
    for label in ax.get_yticklabels():
        label.set_fontweight('bold')
    
    # Enhancing styling
    for spine in ax.spines.values():
        spine.set_linewidth(3)
    
    # Setting tick parameters
    ax.tick_params(axis='both', which='major', labelsize=22, width=3, labelcolor='black')
    ax.tick_params(axis='both', which='minor', width=2, length=8)
    
    # Using tight layout
    plt.tight_layout()
    
    # Saving the enhanced plot
    plot_path = os.path.join(save_dir, 'information_transmission_hd.png')
    plt.savefig(plot_path, dpi=dpi, bbox_inches='tight', facecolor='white')
    plt.close()

def calculate_digital_twin_metrics(pt, methods, window_size=10, prediction_horizon=5):
    """
    Calculate metrics that show the impact of synchronization on digital twin performance.
    
    Args:
        pt: Original time series data
        methods: Dictionary of synchronization methods
        window_size: Window size for calculating local metrics
        prediction_horizon: How far ahead to predict
    
    Returns:
        Dictionary containing digital twin performance metrics
    """
    dt_metrics = {}
    
    for name, method_func in methods.items():
        state, sync_idx = method_func()
        
        # 1. State Representation Fidelity
        # How well does the digital twin represent the current state?
        instantaneous_error = np.abs(pt - state)
        representation_fidelity = 1 - (instantaneous_error / np.max(pt))  # Normalized fidelity
        
        # 2. Prediction Accuracy
        # How well can the digital twin predict future states?
        prediction_errors = []
        for i in range(len(pt) - prediction_horizon):
            # Simple prediction based on current digital twin state and trend
            if i > 0:
                trend = state[i] - state[i-1] if i > 0 else 0
                predicted = state[i] + trend * prediction_horizon
                actual_future = pt[i + prediction_horizon]
                pred_error = abs(predicted - actual_future) / np.max(pt)
                prediction_errors.append(pred_error)
        
        # 3. Synchronization Lag Impact
        # How much lag exists between real events and digital twin updates?
        sync_lags = []
        if sync_idx:
            for i, sync_point in enumerate(sync_idx):
                # Finding the actual event that triggered this sync
                # For simplicity, assume events are significant changes in the data
                if sync_point > 0:
                    actual_change_point = sync_point
                    # Looking backwards to find when the change actually started
                    for j in range(max(0, sync_point-5), sync_point):
                        if abs(pt[j+1] - pt[j]) > np.std(pt) * 0.5:  # Threshold for "significant change"
                            actual_change_point = j
                            break
                    lag = (sync_point - actual_change_point) * dt
                    sync_lags.append(max(0, lag))
        
        # 4. Decision Quality Impact
        # How would decision-making be affected by the digital twin accuracy?
        decision_quality = []
        threshold = np.mean(pt)  # Simple threshold-based decision
        for i in range(len(pt)):
            real_decision = 1 if pt[i] > threshold else 0
            dt_decision = 1 if state[i] > threshold else 0
            decision_quality.append(1 if real_decision == dt_decision else 0)
        
        # 5. Resource Allocation Efficiency
        # How efficiently would resources be allocated based on DT state?
        resource_efficiency = []
        for i in range(len(pt)):
            # Simulating resource allocation: allocate resources proportional to predicted load
            required_resources = pt[i] / np.max(pt)  # Normalized required resources
            allocated_resources = state[i] / np.max(pt)  # Normalized allocated resources
            # Efficiency = 1 - |over_allocation + under_allocation|
            if allocated_resources >= required_resources:
                # Over-allocation penalty
                efficiency = 1 - (allocated_resources - required_resources) * 0.5
            else:
                # Under-allocation penalty (more severe)
                efficiency = 1 - (required_resources - allocated_resources) * 1.5
            resource_efficiency.append(max(0, efficiency))
        
        dt_metrics[name] = {
            'representation_fidelity': np.array(representation_fidelity),
            'prediction_accuracy': 1 - np.array(prediction_errors) if prediction_errors else np.array([0.8] * 10),
            'sync_lags': sync_lags if sync_lags else [0.1],  # Default small lag if no syncs
            'decision_quality': np.array(decision_quality),
            'resource_efficiency': np.array(resource_efficiency),
            'avg_representation_fidelity': np.mean(representation_fidelity),
            'avg_prediction_accuracy': np.mean(prediction_errors) if prediction_errors else 0.2,
            'avg_sync_lag': np.mean(sync_lags) if sync_lags else 0.1,
            'decision_accuracy': np.mean(decision_quality),
            'avg_resource_efficiency': np.mean(resource_efficiency)
        }
    
    return dt_metrics

def plot_digital_twin_impact_comprehensive(pt, methods, dt_metrics, save_dir, dpi=1200):
    """
    Simple, clear 'dt_state_tracking' plot with enhanced bold styling and large readable legend.
    - Single plot showing real network state and each method
    - No scatter markers on lines
    - Large, clear legend with MAE in labels
    """
    plt.style.use('seaborn-v0_8-whitegrid')

    colors_map = {
        'Adaptive Event-Based': ORANGE_COLOR,
        'MPC': BLUE_COLOR,
        'Kalman': GREEN_COLOR,
        'RL': PURPLE_COLOR
    }

    time_axis = np.arange(len(pt))

    fig, ax = plt.subplots(figsize=(20, 14), dpi=dpi) 

    # Ploting real network state
    ax.plot(time_axis, pt, color='k', linewidth=5, alpha=0.9, label='Real Network State')

    # Ploting each method state and compute MAE for legend
    for name, method_func in methods.items():
        try:
            state, sync_idx = method_func()

            # Ensuring state is same length as pt for plotting/MAE
            if len(state) < len(pt):
                state = np.concatenate([state, np.full(len(pt) - len(state), state[-1])])
            elif len(state) > len(pt):
                state = state[:len(pt)]

            mae = np.mean(np.abs(pt - state))
            ax.plot(time_axis, state,
                    linestyle='--',
                    linewidth=4.5,
                    alpha=0.95,
                    color=colors_map.get(name, '#333333'),
                    label=f'{name} (MAE={mae:.3f})')

        except Exception as e:
            print(f"Warning: Could not plot {name}: {e}")
            continue

    ax.set_title('Digital Twin vs Real Network State Tracking', fontsize=28, fontweight='bold', pad=35)
    ax.set_xlabel('Time Steps', fontsize=24, fontweight='bold')
    ax.set_ylabel('Network Load (packets/sec)', fontsize=24, fontweight='bold')
    ax.grid(True, alpha=0.3, linewidth=1.5)
    ax.set_xlim(0, len(pt) - 1)

    # Making all tick labels bold
    for label in ax.get_xticklabels():
        label.set_fontweight('bold')
    for label in ax.get_yticklabels():
        label.set_fontweight('bold')

    # Large, clear legend with compact horizontal layout
    legend = ax.legend(fontsize=16, 
                      loc='upper right', 
                      frameon=True, 
                      fancybox=True, 
                      shadow=True,
                      framealpha=0.98,  
                      prop={'weight': 'bold', 'size': 16},
                      bbox_to_anchor=(0.99, 0.99), 
                      borderpad=0.8,  
                      columnspacing=0.5,  
                      handlelength=2,  
                      handletextpad=0.5,  
                      labelspacing=0.4) 
    
    # Enhanced legend frame
    legend.get_frame().set_linewidth(3)
    legend.get_frame().set_edgecolor('black')
    legend.get_frame().set_facecolor('white')
    
    # Making legend text even more prominent
    for text in legend.get_texts():
        text.set_fontweight('bold')
        text.set_fontsize(18)

    # Enhanced spines
    for spine in ax.spines.values():
        spine.set_linewidth(3)

    ax.tick_params(axis='both', labelsize=20, width=3, labelcolor='black')
    plt.tight_layout()

    # Saving the dt_state_tracking plot
    plot_path = os.path.join(save_dir, 'dt_state_tracking.png')
    plt.savefig(plot_path, dpi=dpi, bbox_inches='tight', facecolor='white')
    plt.close()

    return plot_path

def print_digital_twin_impact_summary(dt_metrics):
    """
    Print a comprehensive summary of digital twin impact metrics.
    """
    print("\n" + "="*80)
    print("DIGITAL TWIN IMPACT ANALYSIS SUMMARY")
    print("="*80)
    
    print("\nüéØ KEY PERFORMANCE INDICATORS:")
    print("-" * 50)
    
    for method in dt_metrics:
        print(f"\nüìä {method.upper()}:")
        print(f"   ‚Ä¢ Representation Fidelity: {dt_metrics[method]['avg_representation_fidelity']:.3f}")
        print(f"   ‚Ä¢ Decision Accuracy:       {dt_metrics[method]['decision_accuracy']:.3f}")
        print(f"   ‚Ä¢ Resource Efficiency:     {dt_metrics[method]['avg_resource_efficiency']:.3f}")
        print(f"   ‚Ä¢ Average Sync Lag:        {dt_metrics[method]['avg_sync_lag']:.3f} seconds")
        print(f"   ‚Ä¢ Prediction Error:        {dt_metrics[method]['avg_prediction_accuracy']:.3f}")
    
    # Finding best performing method for each metric
    print(f"\nüèÜ BEST PERFORMING METHODS:")
    print("-" * 40)
    
    best_fidelity = max(dt_metrics, key=lambda x: dt_metrics[x]['avg_representation_fidelity'])
    best_decisions = max(dt_metrics, key=lambda x: dt_metrics[x]['decision_accuracy'])
    best_efficiency = max(dt_metrics, key=lambda x: dt_metrics[x]['avg_resource_efficiency'])
    best_lag = min(dt_metrics, key=lambda x: dt_metrics[x]['avg_sync_lag'])
    
    print(f"   ‚Ä¢ Best Representation Fidelity: {best_fidelity}")
    print(f"   ‚Ä¢ Best Decision Accuracy:       {best_decisions}")
    print(f"   ‚Ä¢ Best Resource Efficiency:     {best_efficiency}")
    print(f"   ‚Ä¢ Lowest Synchronization Lag:   {best_lag}")
    
    print(f"\nüí° DIGITAL TWIN IMPLICATIONS:")
    print("-" * 40)
    print("   ‚Ä¢ Higher fidelity = More accurate network state representation")
    print("   ‚Ä¢ Better decision accuracy = Improved automated responses")
    print("   ‚Ä¢ Higher efficiency = Optimal resource allocation")
    print("   ‚Ä¢ Lower lag = Faster response to network changes")

# Main execution
if __name__ == '__main__':
    # Getting the directory where the script is located
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    print("="*80)
    print("COMPREHENSIVE SYNCHRONIZATION ANALYSIS")
    print("="*80)
    
    # Training PPO model
    print("\nü§ñ Training the PPO model...")
    ppo_model, ppo_env = train_rl(data, timesteps=300_000)
    print("‚úÖ PPO model training completed!")
    
    # Defining synchronization methods to evaluate
    methods = {
        'Adaptive Event-Based': lambda: adaptive_event_sync(data, 2, 0.05),
        'MPC': lambda: mpc_sync(data, 0.05, 5, 3),
        'Kalman': lambda: kalman_sync(data, 0.1, 1),
        'RL': lambda: rl_event_sync(data, 0.05, ppo_model, ppo_env)
    }
    
    print("\nüìä Performing single-run evaluation...")
    # Evaluating methods - single run
    results = evaluate(data, methods)
    
    # Printing single-run results
    print("\n=== SINGLE-RUN METRICS ===")
    for r in results:
        print(f"{r['method']}: MAE={r['mae']:.3f}, RMSE={r['rmse']:.3f}, Syncs={r['syncs']}")
    
    print("\nCreating single-run visualizations...")
    # Plotting single-run results
    plot_comparison(results, script_dir)
    plot_sync_counts(results, script_dir)
    plot_cumulative_error(data, methods, script_dir)
    print("‚úÖ Single-run plots completed!")
    
    print("\nRunning multiple evaluations for box plot analysis...")
    # Multiple evaluation runs for box plot analysis
    all_results = run_multiple_evaluations(data, methods, ppo_model, ppo_env, n_runs=50)
    print("‚úÖ Multiple evaluations completed!")
    
    print("\nCreating box plot analysis...")
    # Creating box plots
    box_plot_path = create_perfect_box_plot(all_results, script_dir)
    print("‚úÖ Box plot analysis completed!")
    
    print("\nGenerating statistical summary...")
    # Printing detailed statistical summary
    print_statistical_summary(all_results)
    
    print("\nCalculating information metrics...")
    # Calculating and plotting information metrics
    info_metrics = calculate_information_metrics(data, methods)
    plot_information_metrics(info_metrics, script_dir)
    plot_error_vs_information(info_metrics, script_dir)
    print("‚úÖ Information metrics analysis completed!")
    
    print("\nTracking information transmission...")
    # Tracking information transmission
    info_tracking = track_information_transmission(data, methods)
    # Plotting information per sync event
    plot_information_per_sync_event_hd(info_tracking, script_dir)
    print("‚úÖ Information transmission tracking completed!")
    
    print("\nCalculating digital twin impact metrics...")
    # Calculating digital twin performance metrics
    dt_metrics = calculate_digital_twin_metrics(data, methods)
    
    print(" Creating digital twin impact visualization...")
    # Creating comprehensive digital twin impact plot
    dt_plot_path = plot_digital_twin_impact_comprehensive(data, methods, dt_metrics, script_dir)
    
    print(" Generating digital twin impact summary...")
    # Printing digital twin impact summary
    print_digital_twin_impact_summary(dt_metrics)
    print("‚úÖ Digital twin impact analysis completed!")
    
    print("\n" + "="*80)
    print("ANALYSIS COMPLETE!")
    print("="*80)
    print("\nüìÅ Generated Files:")
    print(f"   ‚Ä¢ performance_comparison_hd.png - Single-run bar chart comparison")
    print(f"   ‚Ä¢ sync_counts_hd.png - Synchronization event frequency")
    print(f"   ‚Ä¢ cumulative_error_hd.png - Cumulative error over time")
    print(f"   ‚Ä¢ performance_boxplot_perfect.png - Distribution box plots")
    print(f"   ‚Ä¢ information_metrics.png - Information transfer analysis")
    print(f"   ‚Ä¢ error_vs_information.png - Error vs information trade-off")
    print(f"   ‚Ä¢ information_transmission_hd.png - Information transmission timeline")
    print(f"   ‚Ä¢ dt_state_tracking.png - Digital twin state tracking")
    print(f"\nüìç All plots saved to: {script_dir}")
    
    print("\nSummary of Analysis:")
    print("   ‚úì Single-run performance comparison")
    print("   ‚úì Multi-run statistical distribution analysis")
    print("   ‚úì Box plots showing performance variability")
    print("   ‚úì Information theory analysis")
    print("   ‚úì Error vs bandwidth trade-off analysis")
    print("   ‚úì Digital twin impact analysis")
    print("   ‚úì Comprehensive statistical summaries")
    
    print("\nThe analysis provides insights into:")
    print("   ‚Ä¢ Method performance consistency (via box plots)")
    print("   ‚Ä¢ Information efficiency trade-offs")
    print("   ‚Ä¢ Synchronization event patterns")
    print("   ‚Ä¢ Statistical significance of differences")
    print("   ‚Ä¢ Digital twin performance implications")
    print("\nDone! All visualizations and analysis completed successfully.")
